Starting training...
MEMORY BEFORE LOOP:  |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 172342 KiB | 685566 KiB |    835 MiB | 683629 KiB |
|       from large pool | 165376 KiB | 672568 KiB |    817 MiB | 671416 KiB |
|       from small pool |   6966 KiB |  12998 KiB |     18 MiB |  12213 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 727040 KiB | 727040 KiB | 727040 KiB |      0 B   |
|       from large pool | 712704 KiB | 712704 KiB | 712704 KiB |      0 B   |
|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  29324 KiB |  74728 KiB | 466379 KiB | 437055 KiB |
|       from large pool |  28160 KiB |  68096 KiB | 439552 KiB | 411392 KiB |
|       from small pool |   1164 KiB |   6767 KiB |  26827 KiB |  25663 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| Active allocs         |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      24    |      24    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |      21    |      52    |      43    |
|       from large pool |       7    |      14    |      33    |      26    |
|       from small pool |       2    |       7    |      19    |      17    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
Training:   0%|          | 0/2997 [00:00<?, ?it/s]

MEMORY BEFORE FEATURE EXTRACTION:  |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 320428 KiB | 689676 KiB |    984 MiB | 687728 KiB |
|       from large pool | 313400 KiB | 676608 KiB |    965 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 320428 KiB | 689676 KiB |    984 MiB | 687728 KiB |
|       from large pool | 313400 KiB | 676608 KiB |    965 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 319342 KiB | 685566 KiB |    979 MiB | 683629 KiB |
|       from large pool | 312376 KiB | 672568 KiB |    960 MiB | 671416 KiB |
|       from small pool |   6966 KiB |  12998 KiB |     18 MiB |  12213 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 727040 KiB | 727040 KiB | 727040 KiB |      0 B   |
|       from large pool | 712704 KiB | 712704 KiB | 712704 KiB |      0 B   |
|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  54356 KiB |  74728 KiB | 491411 KiB | 437055 KiB |
|       from large pool |  53192 KiB |  68096 KiB | 464584 KiB | 411392 KiB |
|       from small pool |   1164 KiB |   6767 KiB |  26827 KiB |  25663 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     518    |     754    |    1222    |     704    |
|       from large pool |      37    |      73    |     109    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| Active allocs         |     518    |     754    |    1222    |     704    |
|       from large pool |      37    |      73    |     109    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      24    |      24    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      10    |      21    |      53    |      43    |
|       from large pool |       8    |      14    |      34    |      26    |
|       from small pool |       2    |       7    |      19    |      17    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 248, in <module>
    main()
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 185, in main
    train_metrics = train_epoch(model, train_loader, optimizer, device)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 72, in train_epoch
    frame_features = _extract_features_for_identity(model, frames)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 34, in _extract_features_for_identity
    identity_features = model(batch_frames)[0]
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/AdaFace/net.py", line 352, in forward
    x = module(x)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/AdaFace/net.py", line 170, in forward
    shortcut = self.shortcut_layer(x)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/pooling.py", line 213, in forward
    return F.max_pool2d(
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/_jit_internal.py", line 624, in fn
    return if_false(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/functional.py", line 830, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 86.19 MiB is free. Including non-PyTorch memory, this process has 30.08 GiB memory in use. Process 1468312 has 400.00 MiB memory in use. Process 1468389 has 400.00 MiB memory in use. Process 1468466 has 400.00 MiB memory in use. Process 1469540 has 400.00 MiB memory in use. Of the allocated memory 29.10 GiB is allocated by PyTorch, and 636.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
