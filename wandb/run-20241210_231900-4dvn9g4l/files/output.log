Starting training...
MEMORY BEFORE LOOP:  |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 172342 KiB | 685566 KiB |    835 MiB | 683629 KiB |
|       from large pool | 165376 KiB | 672568 KiB |    817 MiB | 671416 KiB |
|       from small pool |   6966 KiB |  12998 KiB |     18 MiB |  12213 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 727040 KiB | 727040 KiB | 727040 KiB |      0 B   |
|       from large pool | 712704 KiB | 712704 KiB | 712704 KiB |      0 B   |
|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  29324 KiB |  74728 KiB | 466379 KiB | 437055 KiB |
|       from large pool |  28160 KiB |  68096 KiB | 439552 KiB | 411392 KiB |
|       from small pool |   1164 KiB |   6767 KiB |  26827 KiB |  25663 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| Active allocs         |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      24    |      24    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |      21    |      52    |      43    |
|       from large pool |       7    |      14    |      33    |      26    |
|       from small pool |       2    |       7    |      19    |      17    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
Traceback (most recent call last):                
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 276, in <module>
    main()
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 213, in main
    train_metrics = train_epoch(model, train_loader, optimizer, device)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 93, in train_epoch
    with torch.autocast(device_type=device, dtype=torch.bfloat16):
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 226, in __init__
    raise ValueError(
ValueError: Expected `device_type` of type `str`, got: `<class 'torch.device'>`
