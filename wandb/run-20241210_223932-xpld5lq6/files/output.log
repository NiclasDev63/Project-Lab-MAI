Starting training...
MEMORY BEFORE LOOP:  |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 172342 KiB | 685566 KiB |    835 MiB | 683629 KiB |
|       from large pool | 165376 KiB | 672568 KiB |    817 MiB | 671416 KiB |
|       from small pool |   6966 KiB |  12998 KiB |     18 MiB |  12213 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 727040 KiB | 727040 KiB | 727040 KiB |      0 B   |
|       from large pool | 712704 KiB | 712704 KiB | 712704 KiB |      0 B   |
|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  29324 KiB |  74728 KiB | 466379 KiB | 437055 KiB |
|       from large pool |  28160 KiB |  68096 KiB | 439552 KiB | 411392 KiB |
|       from small pool |   1164 KiB |   6767 KiB |  26827 KiB |  25663 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| Active allocs         |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      24    |      24    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |      21    |      52    |      43    |
|       from large pool |       7    |      14    |      33    |      26    |
|       from small pool |       2    |       7    |      19    |      17    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
Training:   0%|          | 0/1499 [00:00<?, ?it/s]

MEMORY BEFORE FEATURE EXTRACTION:  |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 468340 KiB | 689676 KiB |   1128 MiB | 687728 KiB |
|       from large pool | 461312 KiB | 676608 KiB |   1110 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 468340 KiB | 689676 KiB |   1128 MiB | 687728 KiB |
|       from large pool | 461312 KiB | 676608 KiB |   1110 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 466342 KiB | 685566 KiB |   1123 MiB | 683629 KiB |
|       from large pool | 459376 KiB | 672568 KiB |   1104 MiB | 671416 KiB |
|       from small pool |   6966 KiB |  12998 KiB |     18 MiB |  12213 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    998 MiB |    998 MiB |    998 MiB |      0 B   |
|       from large pool |    984 MiB |    984 MiB |    984 MiB |      0 B   |
|       from small pool |     14 MiB |     14 MiB |     14 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  29324 KiB |  74728 KiB | 466379 KiB | 437055 KiB |
|       from large pool |  28160 KiB |  68096 KiB | 439552 KiB | 411392 KiB |
|       from small pool |   1164 KiB |   6767 KiB |  26827 KiB |  25663 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     518    |     754    |    1222    |     704    |
|       from large pool |      37    |      73    |     109    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| Active allocs         |     518    |     754    |    1222    |     704    |
|       from large pool |      37    |      73    |     109    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      25    |      25    |      25    |       0    |
|       from large pool |      18    |      18    |      18    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |      21    |      52    |      43    |
|       from large pool |       7    |      14    |      33    |      26    |
|       from small pool |       2    |       7    |      19    |      17    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 248, in <module>
    main()
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 185, in main
    train_metrics = train_epoch(model, train_loader, optimizer, device)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 72, in train_epoch
    frame_features = _extract_features_for_identity(model, frames)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 34, in _extract_features_for_identity
    identity_features = model(batch_frames)[0]
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/AdaFace/net.py", line 352, in forward
    x = module(x)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/AdaFace/net.py", line 171, in forward
    res = self.res_layer(x)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/functional.py", line 2812, in batch_norm
    return torch.batch_norm(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 74.19 MiB is free. Including non-PyTorch memory, this process has 30.87 GiB memory in use. Process 1440315 has 400.00 MiB memory in use. Process 1441359 has 400.00 MiB memory in use. Of the allocated memory 29.89 GiB is allocated by PyTorch, and 633.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
