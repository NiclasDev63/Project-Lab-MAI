Starting training...
MEMORY BEFORE LOOP:  |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 173428 KiB | 689676 KiB |    840 MiB | 687728 KiB |
|       from large pool | 166400 KiB | 676608 KiB |    822 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 172342 KiB | 685566 KiB |    835 MiB | 683629 KiB |
|       from large pool | 165376 KiB | 672568 KiB |    817 MiB | 671416 KiB |
|       from small pool |   6966 KiB |  12998 KiB |     18 MiB |  12213 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 727040 KiB | 727040 KiB | 727040 KiB |      0 B   |
|       from large pool | 712704 KiB | 712704 KiB | 712704 KiB |      0 B   |
|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  29324 KiB |  74728 KiB | 466379 KiB | 437055 KiB |
|       from large pool |  28160 KiB |  68096 KiB | 439552 KiB | 411392 KiB |
|       from small pool |   1164 KiB |   6767 KiB |  26827 KiB |  25663 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| Active allocs         |     517    |     754    |    1221    |     704    |
|       from large pool |      36    |      73    |     108    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      24    |      24    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       9    |      21    |      52    |      43    |
|       from large pool |       7    |      14    |      33    |      26    |
|       from small pool |       2    |       7    |      19    |      17    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
Training:   0%|          | 0/2997 [00:00<?, ?it/s]

MEMORY BEFORE FEATURE EXTRACTION:  |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 232228 KiB | 689676 KiB |    898 MiB | 687728 KiB |
|       from large pool | 225200 KiB | 676608 KiB |    879 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 232228 KiB | 689676 KiB |    898 MiB | 687728 KiB |
|       from large pool | 225200 KiB | 676608 KiB |    879 MiB | 675456 KiB |
|       from small pool |   7028 KiB |  13068 KiB |     18 MiB |  12272 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 231142 KiB | 685566 KiB |    893 MiB | 683629 KiB |
|       from large pool | 224176 KiB | 672568 KiB |    874 MiB | 671416 KiB |
|       from small pool |   6966 KiB |  12998 KiB |     18 MiB |  12213 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 727040 KiB | 727040 KiB | 727040 KiB |      0 B   |
|       from large pool | 712704 KiB | 712704 KiB | 712704 KiB |      0 B   |
|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 142556 KiB | 142556 KiB | 579611 KiB | 437055 KiB |
|       from large pool | 141392 KiB | 141392 KiB | 552784 KiB | 411392 KiB |
|       from small pool |   1164 KiB |   6767 KiB |  26827 KiB |  25663 KiB |
|---------------------------------------------------------------------------|
| Allocations           |     518    |     754    |    1222    |     704    |
|       from large pool |      37    |      73    |     109    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| Active allocs         |     518    |     754    |    1222    |     704    |
|       from large pool |      37    |      73    |     109    |      72    |
|       from small pool |     481    |     681    |    1113    |     632    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      24    |      24    |      24    |       0    |
|       from large pool |      17    |      17    |      17    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      10    |      21    |      53    |      43    |
|       from large pool |       8    |      14    |      34    |      26    |
|       from small pool |       2    |       7    |      19    |      17    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 248, in <module>
    {
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 185, in main
    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 72, in train_epoch
    Args:
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/train_intra_loss.py", line 34, in _extract_features_for_identity
    #         identity_features = model(batch_frames)[0]
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/AdaFace/net.py", line 352, in forward
    x = module(x)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/Project-Lab-MAI/AdaFace/net.py", line 171, in forward
    res = self.res_layer(x)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/scratch/kurse/kurs00079/ng33rete/mai/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1512, in forward
    return F.prelu(input, self.weight)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 31.73 GiB of which 12.19 MiB is free. Including non-PyTorch memory, this process has 30.15 GiB memory in use. Process 1498797 has 400.00 MiB memory in use. Process 1498979 has 400.00 MiB memory in use. Process 1499054 has 400.00 MiB memory in use. Process 1499131 has 400.00 MiB memory in use. Of the allocated memory 28.87 GiB is allocated by PyTorch, and 940.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
